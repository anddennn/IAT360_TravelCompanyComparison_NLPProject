{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anddennn/IAT360_TravelCompanyComparison_NLPProject/blob/main/NLP_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "Bue6iJOWjG53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up Python Libraries"
      ],
      "metadata": {
        "id": "UjYJbOawjP42"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blJKGNQZjFpk"
      },
      "outputs": [],
      "source": [
        "#install some Python packages with pip\n",
        "\n",
        "!pip install optuna nltk numpy torch datasets transformers requests beautifulsoup4 pandas evaluate --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check the version we are using\n",
        "\n",
        "!pip freeze | grep -E '^numpy|^torch|^datasets|^transformers|^evaluate'"
      ],
      "metadata": {
        "id": "ZCVONR1sjZFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import requests\n",
        "from bs4 import BeautifulSoup ## for scraping\n",
        "import re"
      ],
      "metadata": {
        "id": "MTT_nACDj4D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "W7-VE6awoPJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate Model"
      ],
      "metadata": {
        "id": "cw-lc0qDkUZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's import the pretrained faster tokenizer from huggingface\n",
        "# source: (https://huggingface.co/distilbert-base-uncased)\n",
        "\n",
        "checkpoint = 'distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_fast=True)\n",
        "tokenizer"
      ],
      "metadata": {
        "id": "MEKUV-z0kW1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scrape for Trust Pilot Reviews"
      ],
      "metadata": {
        "id": "axtHIUpQl8jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scrape first 3 pages of the Expedia, TripAdvisor, Booking.com, Airline Ticket Centre and Gala Travels pages on ca.TrustPilot."
      ],
      "metadata": {
        "id": "DaA6MZRXZvuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def soup2list(src, list_, attr=None):\n",
        "    if attr:\n",
        "        for val in src:\n",
        "            list_.append(val[attr])\n",
        "    else:\n",
        "        for val in src:\n",
        "            list_.append(val.get_text())"
      ],
      "metadata": {
        "id": "b2rykSoTr6tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = []\n",
        "ratings = []\n",
        "\n",
        "for i in range(1, 4): # Loop through pages 1 to 3\n",
        "    url = f'https://ca.trustpilot.com/review/www.expedia.com?page={i}'\n",
        "    r = requests.get(url)\n",
        "    soup = BeautifulSoup(r.text, 'html.parser') # Use r.text and html.parser for robust parsing\n",
        "\n",
        "    # Find review headers with class containing 'styles_reviewHeader'\n",
        "    # and extract 'data-service-review-rating' attribute\n",
        "    soup2list(soup.find_all('div', {'class': re.compile(r'.*styles_reviewHeader.*')}), ratings, attr='data-service-review-rating')\n",
        "\n",
        "    # Find review content divs with class containing 'styles_reviewContent'\n",
        "    # and extract their text content\n",
        "    soup2list(soup.find_all('div', {'class': re.compile(r'.*styles_reviewContent.*')}), reviews)\n"
      ],
      "metadata": {
        "id": "uIGOIyfdl_0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 4): # Loop through pages 1 to 3\n",
        "    url = f'https://ca.trustpilot.com/review/www.tripadvisor.ca?page={i}'\n",
        "    r = requests.get(url)\n",
        "    soup = BeautifulSoup(r.text, 'html.parser') # Use r.text and html.parser for robust parsing\n",
        "\n",
        "    # Find review headers with class containing 'styles_reviewHeader'\n",
        "    # and extract 'data-service-review-rating' attribute\n",
        "    soup2list(soup.find_all('div', {'class': re.compile(r'.*styles_reviewHeader.*')}), ratings, attr='data-service-review-rating')\n",
        "\n",
        "    # Find review content divs with class containing 'styles_reviewContent'\n",
        "    # and extract their text content\n",
        "    soup2list(soup.find_all('div', {'class': re.compile(r'.*styles_reviewContent.*')}), reviews)\n"
      ],
      "metadata": {
        "id": "RJqbbgYViyYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 4): # Loop through pages 1 to 3\n",
        "    url = f'https://ca.trustpilot.com/review/www.booking.com?page={i}'\n",
        "    r = requests.get(url)\n",
        "    soup = BeautifulSoup(r.text, 'html.parser') # Use r.text and html.parser for robust parsing\n",
        "\n",
        "    # Find review headers with class containing 'styles_reviewHeader'\n",
        "    # and extract 'data-service-review-rating' attribute\n",
        "    soup2list(soup.find_all('div', {'class': re.compile(r'.*styles_reviewHeader.*')}), ratings, attr='data-service-review-rating')\n",
        "\n",
        "    # Find review content divs with class containing 'styles_reviewContent'\n",
        "    # and extract their text content\n",
        "    soup2list(soup.find_all('div', {'class': re.compile(r'.*styles_reviewContent.*')}), reviews)\n"
      ],
      "metadata": {
        "id": "aPkr3rwYkxUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 4): # Loop through pages 1 to 3\n",
        "    url = f'https://ca.trustpilot.com/review/www.airlineticketcentre.ca?page={i}'\n",
        "    r = requests.get(url)\n",
        "    soup = BeautifulSoup(r.text, 'html.parser') # Use r.text and html.parser for robust parsing\n",
        "\n",
        "    # Find review headers with class containing 'styles_reviewHeader'\n",
        "    # and extract 'data-service-review-rating' attribute\n",
        "    soup2list(soup.find_all('div', {'class': re.compile(r'.*styles_reviewHeader.*')}), ratings, attr='data-service-review-rating')\n",
        "\n",
        "    # Find review content divs with class containing 'styles_reviewContent'\n",
        "    # and extract their text content\n",
        "    soup2list(soup.find_all('div', {'class': re.compile(r'.*styles_reviewContent.*')}), reviews)\n"
      ],
      "metadata": {
        "id": "FJZwQNenl1xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 4): # Loop through pages 1 to 3\n",
        "    url = f'https://ca.trustpilot.com/review/galatravels.com?page={i}'\n",
        "    r = requests.get(url)\n",
        "    soup = BeautifulSoup(r.text, 'html.parser') # Use r.text and html.parser for robust parsing\n",
        "\n",
        "    # Find review headers with class containing 'styles_reviewHeader'\n",
        "    # and extract 'data-service-review-rating' attribute\n",
        "    soup2list(soup.find_all('div', {'class': re.compile(r'.*styles_reviewHeader.*')}), ratings, attr='data-service-review-rating')\n",
        "\n",
        "    # Find review content divs with class containing 'styles_reviewContent'\n",
        "    # and extract their text content\n",
        "    soup2list(soup.find_all('div', {'class': re.compile(r'.*styles_reviewContent.*')}), reviews)\n",
        "\n",
        "\n",
        "review_data = pd.DataFrame(\n",
        "{\n",
        "   'text':reviews,\n",
        "   'label': ratings\n",
        "})\n"
      ],
      "metadata": {
        "id": "_jQaDNIRjggr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_data"
      ],
      "metadata": {
        "id": "s7vgOUdlttBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to minus 1 from all ratings for training later."
      ],
      "metadata": {
        "id": "Geypc2mXvs83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'label' column to numeric type (it's currently a string from scraping)\n",
        "review_data['label'] = pd.to_numeric(review_data['label'])\n",
        "\n",
        "# Subtract 1 from the 'label' column\n",
        "review_data['label'] = review_data['label'] - 1\n",
        "\n",
        "# Display the updated DataFrame head to confirm the change\n",
        "print(review_data.head())"
      ],
      "metadata": {
        "id": "Bi2gAk_yvhjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Reviews into DataFrame and Make csv"
      ],
      "metadata": {
        "id": "31O9B6I2oLsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the raw reviews to a CSV file\n",
        "import pandas as pd\n",
        "review_data.to_csv('trustpilot_reviews.csv', index=False)\n",
        "print(f\"DataFrame with {len(review_data)} entries (text and label) saved to 'trustpilot_reviews.csv'\")"
      ],
      "metadata": {
        "id": "9ExPLnFegwh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize and Split Dataset"
      ],
      "metadata": {
        "id": "kxbEbGFgiToL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make function for tokenizing dataset."
      ],
      "metadata": {
        "id": "kSKGopf_Z8O7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",  # Ensures uniform input size\n",
        "        max_length=128  # Adjust based on task\n",
        "    )"
      ],
      "metadata": {
        "id": "ZjnEWtXPZ3ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split csv dataset into dictionary for train, test & validate."
      ],
      "metadata": {
        "id": "KHd1tQQudYUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('trustpilot_reviews.csv')\n",
        "# Initial dataset before tokenization, named 'raw_dataset' to avoid confusion with the final 'dataset' DatasetDict\n",
        "raw_dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Tokenize the raw dataset\n",
        "tokenized_dataset = raw_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Rename the 'label' column to 'labels' as expected by the Trainer\n",
        "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# Split the tokenized_dataset into training (80%) and a temporary set (20%)\n",
        "train_test_valid_split = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "# Split the temporary set (train_test_valid_split['test']) into validation (50% of temp) and test (50% of temp)\n",
        "test_valid_split = train_test_valid_split['test'].train_test_split(test_size=0.5, seed=42)\n",
        "\n",
        "# Create a DatasetDict named 'dataset' as requested by the user\n",
        "dataset = {\n",
        "    'train': train_test_valid_split['train'],\n",
        "    'val': test_valid_split['train'],\n",
        "    'test': test_valid_split['test']\n",
        "}\n",
        "\n",
        "# Now 'dataset' is a DatasetDict and can be accessed as dataset[\"train\"][0], etc.\n",
        "print(f\"Dataset split into: {len(dataset['train'])} training samples, {len(dataset['val'])} validation samples, {len(dataset['test'])} test samples.\")\n",
        "print(dataset[\"train\"][0]) # Example access as requested by the user"
      ],
      "metadata": {
        "id": "WewbZ3FCZdD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample tokenized output:"
      ],
      "metadata": {
        "id": "QW5iFow3fRNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[\"train\"][0])"
      ],
      "metadata": {
        "id": "dYvcB5cQdXsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model"
      ],
      "metadata": {
        "id": "oKSGGMJ_o3uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# we setup the training to evaluate the accuracy and f1 scores\n",
        "\n",
        "accuracy_metric = evaluate.load('accuracy')\n",
        "f1_metric = evaluate.load('f1')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    # Changed 'average' from default 'binary' to 'weighted' for multiclass classification\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
        "    return {**accuracy, **f1}"
      ],
      "metadata": {
        "id": "d8L3PjOOfcU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, IntervalStrategy\n",
        "\n",
        "# get bert model with a sequence classification head for sentiment analysis\n",
        "# source: (https://huggingface.co/distilbert-base-uncased)\n",
        "checkpoint = 'distilbert-base-uncased'\n",
        "num_labels = 5\n",
        "id2label = {0:'1 star', 1:'2 stars', 2:'3 stars', 3:'4 stars', 4:'5 stars'}\n",
        "label2id = {'1 star':0, '2 stars':1, '3 stars':2, '4 stars':3, '5 stars':4}\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels, id2label=id2label, label2id=label2id)\n",
        "\n",
        "# setup custom training arguments\n",
        "# 1. store training checkpoints to 'results' output directory\n",
        "# 2. fine-tune for just 1 epoch\n",
        "# 3,4. use 16 as a batch size to speed things up\n",
        "# 5. evaluate validation set every 500 steps (this is the default steps)\n",
        "# 6. load the best model based on the lowest validation loss at the end of training\n",
        "training_args = TrainingArguments(\n",
        "    seed=42,\n",
        "    output_dir = './results',\n",
        "    num_train_epochs = 1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    load_best_model_at_end=True,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = 'epoch'\n",
        ")\n",
        "\n",
        "# setup trainer with custom metrics (accuracy, f1)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['val'],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# disable wandb logging (a v4 huggingface artifact)\n",
        "os.environ['WANDB_DISABLED']= \"true\""
      ],
      "metadata": {
        "id": "wm4zLFhIt6jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test for unfine-tuned model."
      ],
      "metadata": {
        "id": "kV9oyp9Ai14Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(dataset['test'])"
      ],
      "metadata": {
        "id": "ZRaHqD4Siy_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "VrRWHwcvjU3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(dataset['test']) ## evaluate on test set"
      ],
      "metadata": {
        "id": "tOx4BoNmnANO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing with examples"
      ],
      "metadata": {
        "id": "x19VZELD_wLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# create pipeline for sentiment classifier with custom model and tokenizer\n",
        "sentiment_classifier = pipeline(task='sentiment-analysis', model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "jskXwGqzoMNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how our model classifies a bad review (1 star)\n",
        "# this is from (https://ca.trustpilot.com/review/www.expedia.ca?page=5)\n",
        "\n",
        "review = \"\"\"\n",
        "Hote bill error, expedia.ca fault\n",
        "I used to like Expedia. Now I will certainly reconsider further bookings with them.\n",
        "I have booked a hotel near Cancun and the invoice from Expedia included a tax to be charged by the hotel.\n",
        "This is normal, there are various and numerous \"environmental\" taxes these days. However, the hotel actually\n",
        "requested the amount that was 3x more than what Expedia.ca provided in the invoice. As far as I understand,\n",
        "it was Expedia's fault, they calculated it incorrectly. However, Expedia has rejected my claim and even the proposal\n",
        "to compensate me the difference in Expedia points! I guess, this is the warning sign for me - with Expedia,\n",
        "the customer is always wrong.\n",
        "\"\"\"\n",
        "sentiment_classifier(review)"
      ],
      "metadata": {
        "id": "1jTtdiNp_6MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how our model classifies a 5 star review\n",
        "# this is from (https://ca.trustpilot.com/review/www.airlineticketcentre.ca)\n",
        "\n",
        "review = \"\"\"\n",
        "A Grateful Customer's Appreciation for Airline Ticket\n",
        "I’ve been a loyal client of Airline Ticket for over 20 years,\n",
        "and their service has consistently been outstanding.\n",
        "They are incredibly reliable—whether it's booking, inquiries,\n",
        "or last-minute changes, they always deliver with professionalism and care.\n",
        "\n",
        "One of the things I value most is their commitment to personal service.\n",
        "They always answer their landline promptly, and it’s always a real human on\n",
        "the other end—ready to help, not just route you through automated systems.\n",
        "Their customer service is truly exceptional: responsive, knowledgeable, and\n",
        " genuinely dedicated to guiding and supporting customers at any time.\n",
        "\n",
        "I’m especially thankful to Michal, Judy, and most recently Shahir\n",
        "for their continued professionalism and kindness. Their expertise and\n",
        "personal touch make every interaction smooth and reassuring.\n",
        "\n",
        "Thank you for two decades of excellence!\n",
        "\"\"\"\n",
        "sentiment_classifier(review)"
      ],
      "metadata": {
        "id": "dOmMsj3p_0no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning parameters"
      ],
      "metadata": {
        "id": "xZZ32By0GD19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the best parameters using Optuna.It uses a smarter approach to search the hyperparameter space and focuses on promising regions. I’ve used this in several projects, and it often finds better configurations than manual tuning."
      ],
      "metadata": {
        "id": "NNXgUDifNoS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"f1\": f1_score(labels, preds, average=\"weighted\")\n",
        "    }\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # Hyperparameters to tune\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        learning_rate=learning_rate,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        num_train_epochs=1,\n",
        "        weight_decay=0.01,\n",
        "        eval_strategy=\"epoch\",\n",
        "        logging_dir=\"./logs\",\n",
        "        report_to=\"none\",         # avoid wandb warnings\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=dataset[\"train\"],\n",
        "        eval_dataset=dataset[\"test\"],\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate()\n",
        "    return eval_results[\"eval_accuracy\"]\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "print(\"Best params:\", study.best_params)\n"
      ],
      "metadata": {
        "id": "H_o8HtIWfwju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put best parameters in training"
      ],
      "metadata": {
        "id": "PgXPfU2Yzgzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, IntervalStrategy\n",
        "\n",
        "# get bert model with a sequence classification head for sentiment analysis\n",
        "# source: (https://huggingface.co/distilbert-base-uncased)\n",
        "checkpoint = 'distilbert-base-uncased'\n",
        "num_labels = 5\n",
        "id2label = {0:'1 star', 1:'2 stars', 2:'3 stars', 3:'4 stars', 4:'5 stars'}\n",
        "label2id = {'1 star':0, '2 stars':1, '3 stars':2, '4 stars':3, '5 stars':4}\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels, id2label=id2label, label2id=label2id)\n",
        "\n",
        "# setup custom training arguments\n",
        "# 1. store training checkpoints to 'results' output directory\n",
        "# 2. fine-tune for just 1 epoch\n",
        "# 3,4. use 16 as a batch size to speed things up\n",
        "# 5. evaluate validation set every 500 steps (this is the default steps)\n",
        "# 6. load the best model based on the lowest validation loss at the end of training\n",
        "training_args = TrainingArguments(\n",
        "    seed=42,\n",
        "    output_dir = './results',\n",
        "    num_train_epochs = 1,\n",
        "\n",
        "    # Best parameters from Optuna\n",
        "    learning_rate=2.734763905921527e-05,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "\n",
        "    load_best_model_at_end=True,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = 'epoch'\n",
        ")\n",
        "\n",
        "# setup trainer with custom metrics (accuracy, f1)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['val'],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# disable wandb logging (a v4 huggingface artifact)\n",
        "os.environ['WANDB_DISABLED']= \"true\""
      ],
      "metadata": {
        "id": "ie3s05R5QZrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "tE9acp3gQDJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(dataset['test']) ## evaluate on test set"
      ],
      "metadata": {
        "id": "3sVk3PZkJH2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# create pipeline for sentiment classifier with custom model and tokenizer\n",
        "sentiment_classifier = pipeline(task='sentiment-analysis', model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "thOSRXGYwvDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how our model classifies a 1 star review\n",
        "# this is from (https://ca.trustpilot.com/review/www.expedia.ca?page=5)\n",
        "\n",
        "review = \"\"\"\n",
        "Hote bill error, expedia.ca fault\n",
        "I used to like Expedia. Now I will certainly reconsider further bookings with them.\n",
        "I have booked a hotel near Cancun and the invoice from Expedia included a tax to be charged by the hotel.\n",
        "This is normal, there are various and numerous \"environmental\" taxes these days. However, the hotel actually\n",
        "requested the amount that was 3x more than what Expedia.ca provided in the invoice. As far as I understand,\n",
        "it was Expedia's fault, they calculated it incorrectly. However, Expedia has rejected my claim and even the proposal\n",
        "to compensate me the difference in Expedia points! I guess, this is the warning sign for me - with Expedia,\n",
        "the customer is always wrong.\n",
        "\"\"\"\n",
        "sentiment_classifier(review)"
      ],
      "metadata": {
        "id": "NPxrm6VhPycG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how our model classifies a 5 star review\n",
        "# this is from (https://ca.trustpilot.com/review/www.airlineticketcentre.ca)\n",
        "\n",
        "review = \"\"\"\n",
        "A Grateful Customer's Appreciation for Airline Ticket\n",
        "I’ve been a loyal client of Airline Ticket for over 20 years,\n",
        "and their service has consistently been outstanding.\n",
        "They are incredibly reliable—whether it's booking, inquiries,\n",
        "or last-minute changes, they always deliver with professionalism and care.\n",
        "\n",
        "One of the things I value most is their commitment to personal service.\n",
        "They always answer their landline promptly, and it’s always a real human on\n",
        "the other end—ready to help, not just route you through automated systems.\n",
        "Their customer service is truly exceptional: responsive, knowledgeable, and\n",
        " genuinely dedicated to guiding and supporting customers at any time.\n",
        "\n",
        "I’m especially thankful to Michal, Judy, and most recently Shahir\n",
        "for their continued professionalism and kindness. Their expertise and\n",
        "personal touch make every interaction smooth and reassuring.\n",
        "\n",
        "Thank you for two decades of excellence!\n",
        "\"\"\"\n",
        "sentiment_classifier(review)"
      ],
      "metadata": {
        "id": "te_Uzq6Dy_YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how our model classifies a 5 star review\n",
        "# this is from (https://ca.trustpilot.com/review/www.airlineticketcentre.ca)\n",
        "\n",
        "review = \"\"\"\n",
        "A Grateful Customer's Appreciation for Airline Ticket\n",
        "I’ve been a loyal client of Airline Ticket for over 20 years,\n",
        "and their service has consistently been outstanding.\n",
        "They are incredibly reliable—whether it's booking, inquiries,\n",
        "or last-minute changes, they always deliver with professionalism and care.\n",
        "\n",
        "One of the things I value most is their commitment to personal service.\n",
        "They always answer their landline promptly, and it’s always a real human on\n",
        "the other end—ready to help, not just route you through automated systems.\n",
        "Their customer service is truly exceptional: responsive, knowledgeable, and\n",
        " genuinely dedicated to guiding and supporting customers at any time.\n",
        "\n",
        "I’m especially thankful to Michal, Judy, and most recently Shahir\n",
        "for their continued professionalism and kindness. Their expertise and\n",
        "personal touch make every interaction smooth and reassuring.\n",
        "\n",
        "Thank you for two decades of excellence!\n",
        "\"\"\"\n",
        "sentiment_classifier(review)"
      ],
      "metadata": {
        "id": "Js_uWc4oB5gR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}